{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile Min_Max.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <climits>\n",
        "#include <cassert>\n",
        "\n",
        "#define CUDA_CHECK(err) do { \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error: \" << cudaGetErrorString(err) << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl; \\\n",
        "        exit(1); \\\n",
        "    } \\\n",
        "} while(0)\n",
        "\n",
        "__global__ void min_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicMin(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void max_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicMax(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicAdd(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::vector<int> arr = {5, 2, 9, 1, 7, 6, 8, 3, 4};\n",
        "    int size = arr.size();\n",
        "    int* d_arr;\n",
        "    int* d_result;\n",
        "    int result_min = INT_MAX;\n",
        "    int result_max = INT_MIN;\n",
        "    int result_sum = 0;\n",
        "\n",
        "    // Allocate device memory\n",
        "    CUDA_CHECK(cudaMalloc(&d_arr, size * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_result, sizeof(int)));\n",
        "\n",
        "    // Copy data to device\n",
        "    CUDA_CHECK(cudaMemcpy(d_arr, arr.data(), size * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Minimum reduction\n",
        "    CUDA_CHECK(cudaMemcpy(d_result, &result_min, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    min_reduction_kernel<<<(size + 255)/256, 256>>>(d_arr, size, d_result);\n",
        "    CUDA_CHECK(cudaMemcpy(&result_min, d_result, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Maximum reduction\n",
        "    CUDA_CHECK(cudaMemcpy(d_result, &result_max, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    max_reduction_kernel<<<(size + 255)/256, 256>>>(d_arr, size, d_result);\n",
        "    CUDA_CHECK(cudaMemcpy(&result_max, d_result, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Sum reduction\n",
        "    result_sum = 0; // Reset\n",
        "    CUDA_CHECK(cudaMemcpy(d_result, &result_sum, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    sum_reduction_kernel<<<(size + 255)/256, 256>>>(d_arr, size, d_result);\n",
        "    CUDA_CHECK(cudaMemcpy(&result_sum, d_result, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    std::cout << \"Minimum: \" << result_min << \"\\n\"\n",
        "              << \"Maximum: \" << result_max << \"\\n\"\n",
        "              << \"Sum: \" << result_sum << \"\\n\"\n",
        "              << \"Average: \" << static_cast<double>(result_sum)/size << std::endl;\n",
        "\n",
        "    // Cleanup\n",
        "    CUDA_CHECK(cudaFree(d_arr));\n",
        "    CUDA_CHECK(cudaFree(d_result));\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "7_3YJyCk6jSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d7897e-bebe-4662-9ea8-90ba51414081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Min_Max.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 Min_Max.cu -o Min_Max"
      ],
      "metadata": {
        "id": "zyWu-iD8410y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Min_Max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh5-hJKY6dm8",
        "outputId": "099eda92-9799-445d-830e-53476cdfbdcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 1\n",
            "Maximum: 9\n",
            "Sum: 45\n",
            "Average: 5\n"
          ]
        }
      ]
    }
  ]
}