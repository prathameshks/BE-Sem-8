{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y06BZFl27G5f",
        "outputId": "b0b1c6d4-dd8a-4d3a-a657-a0a4813dd001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-uphnabxr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-uphnabxr\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhcIAk6U8Trg",
        "outputId": "0cf8dada-b330-4fd9-8075-53ba58a4bb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Wed Apr 23 07:09:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "void initialize(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        vector[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        cout << vector[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 4;\n",
        "    int* A = new int[N];\n",
        "    int* B = new int[N];\n",
        "    int* C = new int[N];\n",
        "\n",
        "    initialize(A, N);\n",
        "    initialize(B, N);\n",
        "\n",
        "    cout << \"Vector A: \";\n",
        "    print(A, N);\n",
        "    cout << \"Vector B: \";\n",
        "    print(B, N);\n",
        "\n",
        "    int *X, *Y, *Z;\n",
        "    size_t bytes = N * sizeof(int);\n",
        "    cudaMalloc(&X, bytes);\n",
        "    cudaMalloc(&Y, bytes);\n",
        "    cudaMalloc(&Z, bytes);\n",
        "\n",
        "    cudaMemcpy(X, A, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y, B, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(C, Z, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"Addition: \";\n",
        "    print(C, N);\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    cudaFree(X);\n",
        "    cudaFree(Y);\n",
        "    cudaFree(Z);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWx6q7MUfwet",
        "outputId": "4a95f123-0b90-4ff9-8b4f-78e85943422b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When compiling with nvcc, specify the correct target architecture for the GPU you're using. Use either -arch=sm_70 or -arch=sm_60\n"
      ],
      "metadata": {
        "id": "uBaqwvDzhDSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 add.cu -o add\n",
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B3vv6avgUGC",
        "outputId": "53ac2940-1a27-4a17-df3f-bf7d1e1eee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 3 6 7 5 \n",
            "Vector B: 3 5 6 2 \n",
            "Addition: 6 11 13 7 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix.cu\n",
        "#include <iostream>\n",
        "#define N 4  // Size of the matrix (N x N)\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matrixMulKernel(int *A, int *B, int *C, int n) {\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < n; ++i) {\n",
        "            sum += A[row * n + i] * B[i * n + col];\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(int);\n",
        "    int A[N*N], B[N*N], C[N*N];\n",
        "\n",
        "    // Initialize matrices A and B\n",
        "    for (int i = 0; i < N*N; ++i) {\n",
        "        A[i] = i;\n",
        "        B[i] = i;\n",
        "    }\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy input data to device\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((N + 15)/16, (N + 15)/16);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMulKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result\n",
        "    std::cout << \"Result matrix C:\\n\";\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            std::cout << C[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << \"\\n\";\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96FCHchhYm8T",
        "outputId": "11a1b803-226f-4680-8739-2187079ba2b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 matrix.cu -o matrix\n",
        "!./matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRUQWgEIYwqN",
        "outputId": "a71eb469-d50b-4c1f-9564-d06ef9d37d7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result matrix C:\n",
            "56 62 68 74 \n",
            "152 174 196 218 \n",
            "248 286 324 362 \n",
            "344 398 452 506 \n"
          ]
        }
      ]
    }
  ]
}